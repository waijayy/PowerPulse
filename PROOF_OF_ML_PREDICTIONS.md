# Proof of Real ML Predictions - Demonstration Guide

This document provides evidence that the forecast predictions are generated by real Machine Learning models, not hardcoded values.

## üéØ Quick Verification Methods

### 1. **Model Information Endpoint** (Easiest)
Call this endpoint to see detailed model architecture:

```bash
curl http://127.0.0.1:8000/forecast/model-info
```

**What to look for:**
- ‚úÖ Model file sizes (MB) - proves real model files exist
- ‚úÖ Total parameters (e.g., 50,000+ parameters) - too complex to be hardcoded
- ‚úÖ Layer architecture (LSTM layers, Dense layers) - shows neural network structure
- ‚úÖ Input/output shapes - proves it's processing sequences

**Example Response:**
```json
{
  "model_type": "LSTM (Long Short-Term Memory) Neural Network",
  "models": {
    "daily": {
      "total_params": 52301,
      "layers": 5,
      "layer_types": ["InputLayer", "LSTM", "LSTM", "Dense", "Dense"],
      "file_size_mb": 2.45
    }
  }
}
```

---

### 2. **Different Inputs = Different Predictions** (Most Convincing)

Prove predictions change based on input data:

#### Test A: Use Real Dataset
```bash
curl http://127.0.0.1:8000/forecast/predict/week
```
**Result:** Predictions based on last 30 days from House_4.csv

#### Test B: Provide Custom History Data
```bash
curl -X POST http://127.0.0.1:8000/forecast/predict/daily \
  -H "Content-Type: application/json" \
  -d '{
    "history_data": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],
    "mode": "week"
  }'
```
**Result:** Different predictions (lower values around ~10 kWh)

#### Test C: High Usage Pattern
```bash
curl -X POST http://127.0.0.1:8000/forecast/predict/daily \
  -H "Content-Type: application/json" \
  -d '{
    "history_data": [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25],
    "mode": "week"
  }'
```
**Result:** Different predictions (higher values around ~25 kWh)

**‚úÖ If predictions change based on input, it's REAL ML, not hardcoded!**

---

### 3. **Show Model Files** (Physical Proof)

**Location:** `ml-service/models/`

**Files to show:**
- `lstm_daily.h5` - Trained LSTM model (2-5 MB file)
- `lstm_hourly.h5` - Trained hourly model
- `scaler_daily.pkl` - Data scaler (preprocessing)
- `scaler_hourly.pkl` - Hourly scaler

**How to verify:**
```bash
# Show file sizes (proves they're real model files)
ls -lh ml-service/models/*.h5

# Show model was created recently (if you just trained it)
ls -lt ml-service/models/
```

**Why this proves it:**
- Model files are **binary files** (can't be easily faked)
- File sizes are **2-5 MB** (too large for simple hardcoded values)
- Created by TensorFlow/Keras (can verify with `file` command)

---

### 4. **Show Training Script** (Code Proof)

**File:** `ml-service/train_models.py`

**What judges should see:**
- ‚úÖ LSTM architecture definition (lines 50-60)
- ‚úÖ Model training with epochs, validation (lines 140-147)
- ‚úÖ Data preprocessing (scaling, sequences)
- ‚úÖ Model saving code (line 208)

**Key Code Snippets:**

```python
# Line 50-60: Real LSTM Architecture
def build_lstm_model(look_back, output_size=1):
    model = Sequential([
        Input(shape=(look_back, 1)),
        LSTM(50, return_sequences=True),
        LSTM(50, return_sequences=False),
        Dense(25),
        Dense(output_size)
    ])
    model.compile(optimizer='adam', loss='mse', metrics=['mae'])
    return model

# Line 193-200: Real Training Process
history = model.fit(
    X_train, y_train,
    epochs=50,
    batch_size=32,
    validation_data=(X_test, y_test),
    callbacks=[early_stop],
    verbose=1
)
```

**How to demonstrate:**
```bash
# Show the training script
cat ml-service/train_models.py | head -100

# Show it can be run (don't actually train, just show it exists)
python ml-service/train_models.py --help
```

---

### 5. **Show Prediction Code** (Runtime Proof)

**File:** `ml-service/forecast_api.py`

**Key Lines to Show:**

```python
# Line 300-305: Real ML Prediction Process
input_seq = np.array(last_30_days).reshape(-1, 1)
scaled_seq = daily_scaler.transform(input_seq).reshape(1, DAILY_LOOK_BACK, 1)

# THIS IS THE ACTUAL ML PREDICTION
pred_scaled = daily_model.predict(scaled_seq, verbose=0)
pred_vals = daily_scaler.inverse_transform(pred_scaled.reshape(-1, 1)).flatten()
```

**Why this proves it:**
- Uses `model.predict()` - TensorFlow/Keras function
- Data scaling (MinMaxScaler) - standard ML preprocessing
- Reshaping for LSTM input format - proves it's sequence-based ML

---

### 6. **Live Demonstration** (Most Impressive)

**During Presentation:**

1. **Show Model Info:**
   ```bash
   curl http://127.0.0.1:8000/forecast/model-info | python -m json.tool
   ```
   - Point out: "50,000+ parameters", "LSTM layers", "2.5 MB model file"

2. **Show Different Predictions:**
   - Call `/predict/week` twice (might get slightly different results due to model variance)
   - Call `/predict/daily` with different input arrays
   - Show predictions change based on input

3. **Show Model Files:**
   ```bash
   # Windows
   dir ml-service\models\*.h5
   
   # Show file properties (right-click ‚Üí Properties)
   ```

4. **Show Training Script:**
   - Open `train_models.py` in code editor
   - Highlight LSTM architecture
   - Show training code

---

### 7. **Technical Details for Judges**

**Model Architecture:**
- **Type:** LSTM (Long Short-Term Memory) Neural Network
- **Framework:** TensorFlow 2.x / Keras
- **Input:** 30 days of historical energy data (kWh)
- **Output:** 7 days of predicted energy usage (kWh)
- **Architecture:**
  - Input Layer: (30, 1)
  - LSTM Layer 1: 50 units, return_sequences=True
  - LSTM Layer 2: 50 units, return_sequences=False
  - Dense Layer: 25 units
  - Output Layer: 7 units (one per day)

**Training Process:**
- Dataset: House_4.csv (REFIT dataset)
- Training: 80% of data
- Validation: 20% of data
- Epochs: 50 (with early stopping)
- Loss Function: Mean Squared Error (MSE)
- Optimizer: Adam

**Preprocessing:**
- MinMaxScaler: Normalizes data to [0, 1] range
- Sequence Creation: Creates 30-day sliding windows
- Inverse Transform: Converts predictions back to kWh

---

## üé§ Presentation Script

**Opening:**
> "Our forecast predictions are powered by a real LSTM neural network. Let me show you the proof..."

**Step 1 - Model Info:**
> "First, let's check the model architecture. As you can see, we have 50,000+ parameters across 5 layers, including two LSTM layers. This is far too complex to be hardcoded."

**Step 2 - Different Inputs:**
> "Now watch what happens when I change the input data. [Run Test B] The predictions change because the model learns patterns from the input. Hardcoded values wouldn't do this."

**Step 3 - Model Files:**
> "Here are the actual model files - 2.5 MB binary files created by TensorFlow. You can see they were generated during training."

**Step 4 - Training Code:**
> "And here's the training script that created these models. It uses real LSTM architecture and trains on historical data."

**Closing:**
> "So to summarize: we have real model files, real training code, and predictions that adapt to input data. This is genuine machine learning, not hardcoded values."

---

## ‚úÖ Checklist for Judges

- [ ] Model info endpoint shows architecture details
- [ ] Predictions change when input data changes
- [ ] Model files exist and are proper size (2-5 MB)
- [ ] Training script exists and shows LSTM code
- [ ] Prediction code uses `model.predict()` from TensorFlow
- [ ] Different API calls return different (but reasonable) predictions

---

## üìù Additional Notes

**If judges ask: "Can you retrain the model?"**
- Yes! Run `python ml-service/train_models.py`
- This will create new model files with different weights
- Predictions will change (proving they're not hardcoded)

**If judges ask: "How do we know the model is actually being used?"**
- Show the code: `daily_model.predict()` is called
- Show model loading logs in server console
- Show `/model-info` endpoint confirms models are loaded

**If judges ask: "What if you just memorized the outputs?"**
- Show predictions change with different inputs
- Show model has 50,000+ parameters (too many to memorize)
- Show you can retrain and get different results

---

## üîó Quick Links

- Model Info: `http://127.0.0.1:8000/forecast/model-info`
- Health Check: `http://127.0.0.1:8000/forecast/health`
- Weekly Predictions: `http://127.0.0.1:8000/forecast/predict/week`
- Training Script: `ml-service/train_models.py`
- Model Files: `ml-service/models/`

